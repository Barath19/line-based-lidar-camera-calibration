{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import kornia\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.remove('/opt/ros/kinetic/lib/python2.7/dist-packages')\n",
    "import cv2 as cv\n",
    "from torch import autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = 692.653256; cx = 629.321381; cy = 330.685425\n",
    "p = np.array([ [692.653256, 0.000000, 629.321381, 0.000000],\n",
    "[0.000000, 692.653256, 330.685425, 0.000000],\n",
    "[0.000000, 0.000000, 1.000000, 0.000000] ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_pix_cam_coord(pix):\n",
    "    px = (pix[0] - cx)/f\n",
    "    py = (pix[1] - cy)/f\n",
    "    return np.array([px,py,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_lid_on_img(lid_pt,R,t,p):\n",
    "    lid_pt = np.append(lid_pt,[1])\n",
    "    t = np.append(t,[1])\n",
    "    T = np.append(R,np.array([0,0,0]).reshape(1,3),axis=0)\n",
    "    T = np.append(T,t.reshape(4,1),axis=1)\n",
    "    tran_pt =  np.dot(T,lid_pt)\n",
    "    proj_lid_pt = np.dot(p,tran_pt).reshape(3,1)\n",
    "    pix = np.array([proj_lid_pt[0]/proj_lid_pt[2],proj_lid_pt[1]/proj_lid_pt[2]]).reshape(2,1)\n",
    "    return pix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_function_rot(N, q, D):\n",
    "    R = kornia.quaternion_to_rotation_matrix(q)\n",
    "    D_rotated = torch.matmul(R,D.double())\n",
    "    B = torch.mm(N,D_rotated)\n",
    "    B = B**2\n",
    "    return B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_function_trans(N, q, T, pt_m):\n",
    "    R = kornia.quaternion_to_rotation_matrix(q)\n",
    "    m_rotated = torch.matmul(R.double(), pt_m.double())\n",
    "    m_trans = torch.add(m_rotated, T)\n",
    "    B = torch.mm(N,m_trans)\n",
    "    B = B**2\n",
    "    return B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.67357658 -0.70141032 -0.23306255] [-0.7053016   0.65920346 -0.26076895]\n"
     ]
    }
   ],
   "source": [
    "cam_pnt_a = np.array([507,218])\n",
    "cam_pnt_b = np.array([381,339])\n",
    "cam_pnt_c = np.array([524,492])\n",
    "\n",
    "N_ab = np.cross(convert_pix_cam_coord(cam_pnt_a), convert_pix_cam_coord(cam_pnt_b))\n",
    "N_ab = N_ab/(np.sqrt(np.dot(N_ab,N_ab)))\n",
    "N_bc = np.cross(convert_pix_cam_coord(cam_pnt_b), convert_pix_cam_coord(cam_pnt_c))\n",
    "N_bc = N_bc/(np.sqrt(np.dot(N_bc,N_bc)))\n",
    "\n",
    "Ncap = np.append(N_ab.reshape(3,1),N_bc.reshape(3,1),axis=1)\n",
    "print(N_ab,N_bc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.34198898  0.359217  ]\n",
      " [-0.317811    0.420697  ]\n",
      " [ 0.00065005 -0.02569997]]\n"
     ]
    }
   ],
   "source": [
    "lid_pnt_a = torch.FloatTensor([-0.475146,-0.195425,1.86017])\n",
    "lid_pnt_b = torch.FloatTensor([-0.817135,0.122386,1.85952])\n",
    "lid_pnt_c = torch.FloatTensor([-0.457918,0.543083,1.83382])\n",
    "\n",
    "# R_temp = torch.FloatTensor([[0.866,0.5,0],[-0.5,0.866,0],[0,0,1]])\n",
    "\n",
    "# lid_pnt_a = torch.mm(R_temp,lid_pnt_a.view(3,1))\n",
    "# lid_pnt_b = torch.mm(R_temp,lid_pnt_b.view(3,1))\n",
    "# lid_pnt_c = torch.mm(R_temp,lid_pnt_c.view(3,1))\n",
    "\n",
    "dir_ab = lid_pnt_a - lid_pnt_b\n",
    "dir_cb = lid_pnt_c - lid_pnt_b\n",
    "\n",
    "dir = np.append(dir_ab.reshape(3,1), dir_cb.reshape(3,1), axis=1)\n",
    "print(dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_init = np.array([0,0,0,1])\n",
    "T_init = np.array([0,0,0])\n",
    "q = autograd.Variable(torch.from_numpy(q_init.astype(dtype=float)),requires_grad=True)\n",
    "T = autograd.Variable(torch.from_numpy(T_init.astype(dtype=float)),requires_grad=True)\n",
    "D = autograd.Variable(dir_cb.view(3,1))\n",
    "N = autograd.Variable(torch.from_numpy(N_bc.astype(dtype=float)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = autograd.Variable(torch.FloatTensor([0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0378e-09]], dtype=torch.float64, grad_fn=<PowBackward0>) tensor([ 0.0047, -0.0056, -0.0268,  0.9996], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "for i in range(1000):\n",
    "    total = cost_function_rot(N.view(1,3), q, D)\n",
    "    total.backward()\n",
    "    q.data -= .1 * q.grad.data\n",
    "    q.data = kornia.normalize_quaternion(q.data)\n",
    "print(total,q.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.99850357  0.05347128 -0.01146517]\n",
      " [-0.05357574  0.99852318 -0.00900583]\n",
      " [ 0.01096668  0.00960661  0.99989372]]\n"
     ]
    }
   ],
   "source": [
    "R_final = kornia.quaternion_to_rotation_matrix(q.data).numpy()\n",
    "print(R_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_trans = autograd.Variable(torch.FloatTensor([0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread(\"/home/chinmay/Downloads/test_image.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0003]], dtype=torch.float64, grad_fn=<PowBackward0>) tensor([ 0.1538, -0.1437,  0.0569], dtype=torch.float64) tensor([-74.8467,  69.9547, -27.6728], dtype=torch.float64)\n",
      "[[501.49307771]\n",
      " [210.94005426]] [[383.63376034]\n",
      " [332.68739181]] [[521.0838231 ]\n",
      " [479.63618002]]\n"
     ]
    }
   ],
   "source": [
    "pt_m = (lid_pnt_c+lid_pnt_b)/2\n",
    "Nbc = autograd.Variable(torch.from_numpy(N_bc.astype(dtype=float)))\n",
    "\n",
    "# pt_m = (lid_pnt_b)\n",
    "# Nbc = autograd.Variable(torch.from_numpy(N_bc.astype(dtype=float)))\n",
    "\n",
    "# dir_ab_proj = project_lid_on_img(dir_ab, R, T)\n",
    "\n",
    "for i in range(100):\n",
    "    total_trans = cost_function_trans(Nbc.view(1,3), q, T.view(3,1), pt_m.view(3,1))\n",
    "    total_trans.backward()\n",
    "    T.data -= .000001 * T.grad.data\n",
    "print(total_trans,T.data,T.grad.data)\n",
    "\n",
    "pix_a = project_lid_on_img(lid_pnt_a,R_final,T.data.numpy(),p)\n",
    "pix_b = project_lid_on_img(lid_pnt_b,R_final,T.data.numpy(),p)\n",
    "pix_c = project_lid_on_img(lid_pnt_c,R_final,T.data.numpy(),p)\n",
    "# pix_a = project_lid_on_img(lid_pnt_a,np.eye(3),np.zeros(3),p)\n",
    "# pix_b = project_lid_on_img(lid_pnt_b,np.eye(3),np.zeros(3),p)\n",
    "# pix_c = project_lid_on_img(lid_pnt_c,np.eye(3),np.zeros(3),p)\n",
    "\n",
    "print(pix_a,pix_b,pix_c)\n",
    "\n",
    "cv.circle(img, tuple(pix_a), 4, (255,0,0), thickness=2, lineType=8, shift=0);\n",
    "cv.circle(img, tuple(pix_b), 4, (255,0,0), thickness=2, lineType=8, shift=0);\n",
    "cv.circle(img, tuple(pix_c), 4, (255,0,0), thickness=2, lineType=8, shift=0);\n",
    "\n",
    "cv.imshow('Transformed lidar pnts',img)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pix_a = project_lid_on_img(lid_pnt_a,R_final,T.data.numpy(),p)\n",
    "pix_b = project_lid_on_img(lid_pnt_b,R_final,T.data.numpy(),p)\n",
    "pix_c = project_lid_on_img(lid_pnt_c,R_final,T.data.numpy(),p)\n",
    "# pix_a = project_lid_on_img(lid_pnt_a,np.eye(3),np.zeros(3),p)\n",
    "# pix_b = project_lid_on_img(lid_pnt_b,np.eye(3),np.zeros(3),p)\n",
    "# pix_c = project_lid_on_img(lid_pnt_c,np.eye(3),np.zeros(3),p)\n",
    "\n",
    "print(pix_a,pix_b,pix_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread(\"/home/chinmay/Downloads/test_image.png\")\n",
    "cv.circle(img, tuple(pix_a), 4, (255,0,0), thickness=2, lineType=8, shift=0);\n",
    "cv.circle(img, tuple(pix_b), 4, (255,0,0), thickness=2, lineType=8, shift=0);\n",
    "cv.circle(img, tuple(pix_c), 4, (255,0,0), thickness=2, lineType=8, shift=0);\n",
    "# cv.imwrite(\"/home/chinmay/Desktop/output_30_rot.png\",img)\n",
    "cv.imshow('Transformed lidar pnts',img)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
