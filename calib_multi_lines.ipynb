{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import kornia\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.remove('/opt/ros/kinetic/lib/python2.7/dist-packages')\n",
    "import cv2 as cv\n",
    "from torch import autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = 692.653256; cx = 629.321381; cy = 330.685425\n",
    "p = np.array([ [692.653256, 0.000000, 629.321381, 0.000000],\n",
    "[0.000000, 692.653256, 330.685425, 0.000000],\n",
    "[0.000000, 0.000000, 1.000000, 0.000000] ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_pix_cam_coord(pix):\n",
    "    px = (pix[0] - cx)/f\n",
    "    py = (pix[1] - cy)/f\n",
    "    return torch.FloatTensor([px,py,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_lid_on_img(lid_pt,R,t,p):\n",
    "    lid_pt = np.append(lid_pt,[1])\n",
    "    t = np.append(t,[1])\n",
    "    T = np.append(R,np.array([0,0,0]).reshape(1,3),axis=0)\n",
    "    T = np.append(T,t.reshape(4,1),axis=1)\n",
    "    tran_pt =  np.dot(T,lid_pt)\n",
    "    proj_lid_pt = np.dot(p,tran_pt).reshape(3,1)\n",
    "    pix = np.array([proj_lid_pt[0]/proj_lid_pt[2],proj_lid_pt[1]/proj_lid_pt[2]]).reshape(2,1)\n",
    "    return pix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_function_trans(N, q, T, pt_m):\n",
    "#     print(N.shape,q.shape,T.shape,pt_m.shape)\n",
    "    R = kornia.quaternion_to_rotation_matrix(q)\n",
    "    m_rotated = torch.matmul(R, pt_m)\n",
    "    m_trans = torch.add(m_rotated, T)\n",
    "    B = N * m_trans\n",
    "    B = torch.sum(B,dim=0)\n",
    "#     B = torch.mm(N,m_trans)\n",
    "#     print(B.shape)\n",
    "    B = B**2\n",
    "    return torch.sum(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_function_rot(N, q, D):\n",
    "    R = kornia.quaternion_to_rotation_matrix(q)\n",
    "    D_rotated = torch.matmul(R,D)\n",
    "    B = N * D_rotated\n",
    "    B = torch.sum(B,dim=0)\n",
    "#     print(\"N\",N)\n",
    "#     print(\"D\",D_rotated)\n",
    "#     print(\"B\",B)\n",
    "    B = B**2\n",
    "    return torch.sum(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1747],\n",
      "        [-0.1819],\n",
      "        [-0.0604]]) tensor([[-0.2209],\n",
      "        [ 0.2065],\n",
      "        [-0.0817]])\n",
      "tensor([[-0.1747, -0.2209],\n",
      "        [-0.1819,  0.2065],\n",
      "        [-0.0604, -0.0817]])\n",
      "tensor([-143., -153.])\n"
     ]
    }
   ],
   "source": [
    "cam_pnt_a = torch.FloatTensor([507,218])\n",
    "cam_pnt_b = torch.FloatTensor([381,339])\n",
    "cam_pnt_c = torch.FloatTensor([524,492])\n",
    "\n",
    "N_ab = torch.cross(convert_pix_cam_coord(cam_pnt_a), convert_pix_cam_coord(cam_pnt_b)).view(3,1)\n",
    "N_bc = torch.cross(convert_pix_cam_coord(cam_pnt_b), convert_pix_cam_coord(cam_pnt_c)).view(3,1)\n",
    "\n",
    "Ncap = torch.cat((N_ab.view(3,1),N_bc.view(3,1)), dim=1)\n",
    "\n",
    "print(N_ab,N_bc)\n",
    "print(Ncap)\n",
    "print(cam_pnt_b-cam_pnt_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1373],\n",
      "        [-0.4462],\n",
      "        [ 0.0007]]) tensor([[ 0.5214],\n",
      "        [ 0.1847],\n",
      "        [-0.0257]])\n",
      "tensor([[ 0.1373,  0.5214],\n",
      "        [-0.4462,  0.1847],\n",
      "        [ 0.0007, -0.0257]])\n"
     ]
    }
   ],
   "source": [
    "lid_pnt_a = torch.FloatTensor([-0.475146,-0.195425,1.86017])\n",
    "lid_pnt_b = torch.FloatTensor([-0.817135,0.122386,1.85952])\n",
    "lid_pnt_c = torch.FloatTensor([-0.457918,0.543083,1.83382])\n",
    "\n",
    "# R_temp = torch.FloatTensor([[0.866,0.5,0],[-0.5,0.866,0],[0,0,1]])\n",
    "\n",
    "# lid_pnt_a = torch.mm(R_temp, lid_pnt_a.view(3,1))\n",
    "# lid_pnt_b = torch.mm(R_temp, lid_pnt_b.view(3,1))\n",
    "# lid_pnt_c = torch.mm(R_temp, lid_pnt_c.view(3,1))\n",
    "\n",
    "dir_ab = lid_pnt_a - lid_pnt_b\n",
    "dir_cb = lid_pnt_c - lid_pnt_b\n",
    "\n",
    "dir = torch.cat((dir_ab.view(3,1), dir_cb.view(3,1)), dim=1)\n",
    "print(dir_ab, dir_cb)\n",
    "print(dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_init = np.array([0,0,0,1])\n",
    "T_init = np.array([0,0,0])\n",
    "q = autograd.Variable(torch.FloatTensor([0,0,0,1]),requires_grad=True)\n",
    "T = autograd.Variable(torch.FloatTensor([0,0,0]),requires_grad=True)\n",
    "# D = autograd.Variable(dir_cb.view(3,1))\n",
    "# N = autograd.Variable(N_bc)\n",
    "D = autograd.Variable(dir)\n",
    "N = autograd.Variable(Ncap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = autograd.Variable(torch.FloatTensor([0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.4518e-06, grad_fn=<SumBackward0>) tensor([-0.0549, -0.0077,  0.2310,  0.9714])\n"
     ]
    }
   ],
   "source": [
    "for i in range(1000):\n",
    "    total = cost_function_rot(N, q, D)\n",
    "    total.backward()\n",
    "    q.data -= .1 * q.grad.data\n",
    "    q.data = kornia.normalize_quaternion(q.data)\n",
    "    q.grad.data.zero_()\n",
    "print(total,q.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_final = kornia.quaternion_to_rotation_matrix(q.data).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0.])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0651e-11, grad_fn=<SumBackward0>) tensor([ 0.2158, -0.3330,  0.0814])\n"
     ]
    }
   ],
   "source": [
    "lid_pts = torch.cat((lid_pnt_a.view(3,1),lid_pnt_c.view(3,1)), dim=1)\n",
    "for i in range(10000):\n",
    "    total_trans = cost_function_trans(N, q, T.view(3,1), lid_pts)\n",
    "    total_trans.backward()\n",
    "    T.data -= .01 * T.grad.data\n",
    "    T.grad.data.zero_()\n",
    "print(total_trans,T.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[505.46985315]\n",
      " [219.47562968]] [[383.45211167]\n",
      " [339.7583912 ]] [[522.06077238]\n",
      " [489.92664123]]\n"
     ]
    }
   ],
   "source": [
    "pix_a = project_lid_on_img(lid_pnt_a,R_final,T.data.numpy(),p)\n",
    "pix_b = project_lid_on_img(lid_pnt_b,R_final,T.data.numpy(),p)\n",
    "pix_c = project_lid_on_img(lid_pnt_c,R_final,T.data.numpy(),p)\n",
    "# pix_a = project_lid_on_img(lid_pnt_a,np.eye(3),np.zeros(3),p)\n",
    "# pix_b = project_lid_on_img(lid_pnt_b,np.eye(3),np.zeros(3),p)\n",
    "# pix_c = project_lid_on_img(lid_pnt_c,np.eye(3),np.zeros(3),p)\n",
    "\n",
    "print(pix_a,pix_b,pix_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(720, 1280, 3)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv.imread(\"/home/chinmay/Downloads/test_image.png\")\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_circled = cv.circle(img, tuple(pix_a), 4, (255,0,0), thickness=2, lineType=8, shift=0)\n",
    "img_circled = cv.circle(img, tuple(pix_b), 4, (255,0,0), thickness=2, lineType=8, shift=0)\n",
    "img_circled = cv.circle(img, tuple(pix_c), 4, (255,0,0), thickness=2, lineType=8, shift=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv.imwrite(\"/home/chinmay/Desktop/output_ml_30_rnt.png\",img_circled)\n",
    "cv.imshow('Transformed lidar pnts',img_circled)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.sum(c,dim=0)\n",
    "def project_lid_on_img(lid_pt,R,t,p):\n",
    "    lid_pt = np.append(lid_pt,[1])\n",
    "    t = np.append(t,[1])\n",
    "    T = np.append(R,np.array([0,0,0]).reshape(1,3),axis=0)\n",
    "    T = np.append(T,t.reshape(4,1),axis=1)\n",
    "    tran_pt =  np.dot(T,lid_pt)\n",
    "    proj_lid_pt = np.dot(p,tran_pt).reshape(3,1)\n",
    "    pix = np.array([proj_lid_pt[0]/proj_lid_pt[2],proj_lid_pt[1]/proj_lid_pt[2]]).reshape(2,1)\n",
    "    return pix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_lid_on_img_1(lid_pt,R,t,p):\n",
    "    lid_pt = torch.cat((torch.from_numpy(lid_pt).float(),torch.FloatTensor([1])))\n",
    "    t = torch.cat((t.float(),torch.FloatTensor([1])))\n",
    "    T = torch.cat((torch.from_numpy(R).float(),torch.FloatTensor([0,0,0]).view(1,3)))\n",
    "    T = torch.cat((T,t.view(4,1)),dim=1)\n",
    "    print(T.shape,lid_pt.shape)\n",
    "    tran_pt =  torch.mm(T,lid_pt.view(4,1))\n",
    "    proj_lid_pt = torch.mm(torch.FloatTensor(p),tran_pt).view(3,1)\n",
    "    pix = torch.FloatTensor([proj_lid_pt[0]/proj_lid_pt[2],proj_lid_pt[1]/proj_lid_pt[2]]).reshape(2,1)\n",
    "    return pix\n",
    "\n",
    "mid_img_ab = (cam_pnt_a + cam_pnt_b) / 2\n",
    "mid_lid_ab = (lid_pnt_a + lid_pnt_b) / 2\n",
    "\n",
    "mid_lid_on_cam = project_lid_on_img_1(mid_lid_ab, R_final, T, p)\n",
    "\n",
    "print(torch.FloatTensor(mid_img_ab), mid_lid_on_cam)\n",
    "e1 = torch.dist(torch.FloatTensor(mid_img_ab), mid_lid_on_cam)\n",
    "# e1.backward()\n",
    "\n",
    "def func(p1,p2):\n",
    "    return torch.add(torch.pow(p1[0]-p2[0],2),torch.pow(p1[1]-p2[1],2))\n",
    "\n",
    "err = autograd.Variable(func(autograd.Variable(torch.FloatTensor(mid_img_ab)),autograd.Variable(mid_lid_on_cam)))\n",
    "err.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.from_numpy(lid_pnt_b)\n",
    "print(type(a))\n",
    "b = torch.cat((a.float() ,torch.FloatTensor([1.])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.FloatTensor([0,0,0]).view(1,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.pow((mid_lid_on_cam[0]-mid_lid_on_cam[1])**2,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.zeros(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
